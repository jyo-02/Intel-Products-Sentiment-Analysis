{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing content: 100%|██████████| 44/44 [56:02<00:00, 76.43s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization complete and saved to output2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the CSV file\n",
    "input_file = 'scraped_processors.csv'  # Replace with your input CSV file path\n",
    "output_file = 'output2.csv'  # Output CSV file path\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_file, encoding='ISO-8859-1')\n",
    "\n",
    "# Initialize the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Function to chunk text\n",
    "def chunk_text(text, max_length=1024):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for word in words:\n",
    "        current_length += len(word) + 1  # +1 for the space\n",
    "        if current_length > max_length:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "            current_length = len(word) + 1\n",
    "        else:\n",
    "            current_chunk.append(word)\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Function to summarize content\n",
    "def summarize_text(text):\n",
    "    if not isinstance(text, str) or len(text) == 0:\n",
    "        return \"\"\n",
    "    \n",
    "    chunks = chunk_text(text)\n",
    "    summarized_chunks = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        input_length = len(chunk.split())\n",
    "        max_length = min(math.ceil(input_length * 0.3), 150)\n",
    "        min_length = min(max_length - 10, 30)  # Ensure min_length is always less than max_length\n",
    "        \n",
    "        if max_length <= 10:  # If the chunk is too small to summarize meaningfully\n",
    "            summarized_chunks.append(chunk)\n",
    "        else:\n",
    "            summary = summarizer(chunk, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "            summarized_chunks.append(summary[0]['summary_text'])\n",
    "    \n",
    "    final_summary = \" \".join(summarized_chunks)\n",
    "    return final_summary\n",
    "\n",
    "# Apply the summarization function to each row in the DataFrame with progress tracking\n",
    "summaries = []\n",
    "for idx, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Summarizing content\"):\n",
    "    processor = row['Processor']\n",
    "    source = row['Source']\n",
    "    content = row['Content']\n",
    "    summary = summarize_text(content)\n",
    "    summaries.append({'Processor': processor, 'Source': source, 'Summary': summary})\n",
    "\n",
    "# Create a DataFrame with the summaries\n",
    "output_df = pd.DataFrame(summaries)\n",
    "\n",
    "# Save the summarized content into a new CSV file\n",
    "output_df.to_csv(\"summarized_processors.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Summarization complete and saved to\", output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
