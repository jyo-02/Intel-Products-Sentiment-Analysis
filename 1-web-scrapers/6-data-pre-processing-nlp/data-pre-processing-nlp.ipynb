{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:95%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b> Intel Review - Data Pre-Processing & NLP</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #3b3745; border-radius: 12px; padding: 20px; box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);\">\n",
    "    <h2 style=\"color: #F1A424; text-align: center;\">Table of Contents</h2>\n",
    "    <ul style=\"list-style: none; padding: 0;\">\n",
    "        <li><a href=\"#section-1\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">1.</span>  Importing Libraries</a></li>\n",
    "        <li><a href=\"#section-2\" style=\"color: white; text-decoration: none; display: flex; align-items: center; padding: 8px 15px; border-radius: 6px; transition: background-color 0.3s;\"><span style=\"margin-right: 10px; font-weight: bold; color: #F1A424;\">2.</span> Data Pre-Processing</a></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-1\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>1 |</span></b> <b>  Importing Libraries</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect, LangDetectException\n",
    "from googletrans import Translator\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kiit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Collecting langdetect\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Collecting googletrans==4.0.0-rc1\n",
      "  Using cached googletrans-4.0.0rc1-py3-none-any.whl\n",
      "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
      "  Using cached httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\kiit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.2)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hstspreload-2024.6.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kiit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Using cached chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Using cached rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Using cached httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Using cached h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Using cached h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Using cached hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Using cached hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\kiit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kiit\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kiit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kiit\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six in c:\\users\\kiit\\appdata\\roaming\\python\\python312\\site-packages (from langdetect) (1.16.0)\n",
      "Using cached httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Using cached httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Using cached h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "Using cached rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading hstspreload-2024.6.1-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.2 MB 217.9 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.0/1.2 MB 217.9 kB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.1/1.2 MB 416.7 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.2/1.2 MB 697.2 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.3/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.7/1.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 3.1 MB/s eta 0:00:00\n",
      "Using cached h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "Using cached hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Using cached hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, langdetect, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.7\n",
      "    Uninstalling idna-3.7:\n",
      "      Successfully uninstalled idna-3.7\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.5\n",
      "    Uninstalling httpcore-1.0.5:\n",
      "      Successfully uninstalled httpcore-1.0.5\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.0\n",
      "    Uninstalling httpx-0.27.0:\n",
      "      Successfully uninstalled httpx-0.27.0\n",
      "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.6.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 langdetect-1.0.9 rfc3986-1.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 4.2.0 requires httpx>=0.25.0, but you have httpx 0.13.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas langdetect googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-1=2\"></a>\n",
    "# <div style=\"padding: 30px; color:white; margin:10; font-size:75%; text-align:left; display:fill; border-radius:10px; background-color:#3b3745\"><b><span style='color:#F1A424'>2 |</span></b> <b>  Data Pre-Processing</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 20px; color:white; margin:5; font-size:100%; text-align:left; display:fill; border-radius:5px; background-color:#3b3745\">\n",
    "    <h2 style=\"font-size: 150%; margin-bottom: 10px;\">Steps to Pre-Processing :</h2>\n",
    "    <b>1. Translating if Review is not English</b> <br>\n",
    "    <b>2. Removing Numbers if exist</b> <br>\n",
    "    <b>3. Removing Special Characters & Punctuations</b> <br>\n",
    "    <b>4. Removing Extra Spaces</b> <br>\n",
    "    <b>5. Converting to Lowercase</b> <br>\n",
    "    <b>6. Removing Duplicates</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangDetectException: No features in text.. Text: ???????????\n",
      "Data cleaning and translation complete. Cleaned data saved to 'cleaned_file.csv'.\n"
     ]
    }
   ],
   "source": [
    "translator = Translator()\n",
    "\n",
    "def detect_and_translate(text):\n",
    "    text = text.strip()  \n",
    "    if not text:\n",
    "        return text  \n",
    "    \n",
    "    try:\n",
    "        # Clean text further (remove non-printable characters)\n",
    "        text = ''.join(filter(lambda x: x in string.printable, text))\n",
    "        \n",
    "        # Detect language\n",
    "        lang = detect(text)\n",
    "        print(f\"Detected language: {lang} for text: {text[:30]}...\")  \n",
    "        \n",
    "        # Translate if not English\n",
    "        if lang != 'en':\n",
    "            translated = translator.translate(text, dest='en')\n",
    "            print(f\"Translated text: {translated.text[:30]}...\")  \n",
    "            return translated.text\n",
    "        else:\n",
    "            return text\n",
    "    \n",
    "    except LangDetectException as e:\n",
    "        print(f\"LangDetectException: {e}. Text: {text}\")  \n",
    "        return text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}. Text: {text}\")  \n",
    "        return text\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def clean_data(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    if 'Review' not in df.columns:\n",
    "        raise ValueError(\"The input file does not contain a 'Review' column.\")\n",
    "    \n",
    "    # Detect and translate non-English text in the 'Review' column\n",
    "    df['Review'] = df['Review'].apply(lambda x: detect_and_translate(str(x)) if isinstance(x, str) else x)\n",
    "    \n",
    "    # Clean text in the 'Review' column\n",
    "    df['Review'] = df['Review'].apply(lambda x: clean_text(x) if isinstance(x, str) else x)\n",
    "    \n",
    "    # Handle missing values\n",
    "    for column in df.columns:\n",
    "        if np.issubdtype(df[column].dtype, np.number):\n",
    "            df[column] = df[column].fillna(df[column].mean())\n",
    "        else:\n",
    "            df[column] = df[column].fillna(df[column].mode()[0])\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    return df\n",
    "\n",
    "file_path = '../5-data/all-products-data.csv'  \n",
    "cleaned_df = clean_data(file_path)\n",
    "\n",
    "if cleaned_df.empty:\n",
    "    print(\"Warning: The cleaned DataFrame is empty.\")\n",
    "\n",
    "# Save the cleaned dataframe to a new CSV file\n",
    "cleaned_df.to_csv('../5-data/transuluted-all-products-data.csv', index=False)\n",
    "\n",
    "print(\"Data cleaning and translation complete. Cleaned data saved to 'cleaned_file.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                   This concludes the analysis presented in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
